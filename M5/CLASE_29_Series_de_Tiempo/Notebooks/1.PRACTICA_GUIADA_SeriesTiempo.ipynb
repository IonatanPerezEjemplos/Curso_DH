{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # settings colab:\n",
    "    import google.colab\n",
    "except ModuleNotFoundError:    \n",
    "    # settings local:\n",
    "    %run \"../../../common/0_notebooks_base_setup.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series de Tiempo - Práctica Guiada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_toc\"></a> \n",
    "## Tabla de Contenidos\n",
    "\n",
    "[1- Intro](#section_intro)\n",
    "\n",
    "[2- Descomposición de una serie de tiempo](#section_descomposicion)\n",
    "\n",
    "$\\hspace{.5cm}$[2.1- Tendencia](#section_tendencia)\n",
    "\n",
    "$\\hspace{.5cm}$[2.2- Estacionalidad](#section_estacionalidad)\n",
    "\n",
    "[3- Primeros modelos para prónosticos](#section_modelos_basicos)\n",
    "\n",
    "$\\hspace{.5cm}$[3.1- Análisis exploratorio y preprocesamiento de los datos](#section_eda_preprocesamiento)\n",
    "\n",
    "$\\hspace{.5cm}$[3.2- Media Constante](#section_media_constante)\n",
    "\n",
    "$\\hspace{.5cm}$[3.3- Random Walk](#section_random_walk)\n",
    "\n",
    "$\\hspace{.5cm}$[3.4- Tendencia Lineal](#section_tendencia_lineal)\n",
    "\n",
    "$\\hspace{.5cm}$[3.5- Tendencia Cuadrática](#section_tendencia_cuadratica)\n",
    "\n",
    "$\\hspace{.5cm}$[3.6- Tendencia Transformación Logarítmica](#section_tendencia_transformacion_log)\n",
    "\n",
    "$\\hspace{.5cm}$[3.7- Tendencia Transformación Logarítmica + Estacionalidad](#section_tendencia_transformacion_log_estacionalidad)\n",
    "\n",
    "$\\hspace{.5cm}$[3.8- Single Exponential Smoothing](#section_exponential_smoothing)\n",
    "\n",
    "[4- Modelos de ciclos para series de tiempo](#section_modelos_ciclos)\n",
    "\n",
    "$\\hspace{.5cm}$[4.1- Series Estacionarias](#section_series_estacionarias)\n",
    "\n",
    "$\\hspace{.5cm}$[4.2- Modelo ARIMA](#section_modelo_arima)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_intro\"></a> \n",
    "###  1- Intro\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "Esta clase sigue principalmente la exposición de *Elements of Forecasting (2001)* de Francis X. Diebold. \n",
    "\n",
    "#### ¿Qué es una serie de tiempo?\n",
    "\n",
    "Podemos definir una **serie de tiempo** como un conjunto de observaciones tomadas en **intervalos regulares** que se encuentran **ordenadas** por el momento en que se produjeron.\n",
    "\n",
    "El análisis de series de tiempo se suele utilizar para proyectar o pronosticar la evolución de una variable a lo largo del tiempo, a partir de información previa sobre esa misma variable. Es decir, tenemos que proyectar una variable determinada (eje y) en función del tiempo (eje x). \n",
    "\n",
    "Un ejemplo de serie de tiempo puede ser la evolución del precio de un determinado activo financiero a lo largo del tiempo como en la siguiente imagen:\n",
    "\n",
    "![image.png](img/Picture1.png)\n",
    "\n",
    "Otros ejemplos pueden ser:\n",
    "\n",
    "- Variables macroeconómicas, como el PBI, inflación, reservas del BCRA, etc.\n",
    "- Ventas de comercios\n",
    "- Consumo energético\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja1\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_seguir_pensando.png\" style=\"align:left\"/> </div>\n",
    "  <div style=\"float:left;width: 85%;\"><label>¿Cuáles podrían ser otros ejemplos de series de tiempo? <br/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_descomposicion\"></a> \n",
    "### 2- Descomposición de una serie de tiempo\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "Existen distintos tipos de modelos para tratar las series de tiempo. \n",
    "Una opción es modelar una serie de tiempo como compuesta por **cuatro componentes**:\n",
    "- **Tendencia**: componente “permanente”, el efecto persiste en el largo plazo. Se puede interpretar como lo que motiva el cambio a largo plazo de la media.\n",
    "- **Estacionalidad**: esta componente aporta movimientos periódicos a la serie.\n",
    "- **Ciclos**: se entiende por cualquier tipo de dinámica no capturada por la tendencia o la estacionalidad. Estamos ante la presencia de ciclos cuando observamos algún tipo de dinámica mediante la cual el presente está vinculado al pasado. No tiene por qué ser un ciclo rígido.\n",
    "- **Componente aleatoria**: son shocks que no presentan un efecto duradero, ya que las suponemos i.i.d. con media 0 y varianza constante.\n",
    "\n",
    "De manera aditiva, podemos decir entonces que: \n",
    "\n",
    "$$ y_t = T_t + S_t + C_t + \\varepsilon_t. $$\n",
    "\n",
    "… donde T es la tendencia, S es el efecto estacional C es el ciclo y $ \\varepsilon $ es el error aleatorio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_tendencia\"></a> \n",
    "#### 2.1- Tendencia\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "La **tendencia** corresponde a la **evolución de largo plazo** de la variable que estamos analizando. Puede ser generada por la lenta evolución y cambios en las preferencias, la tecnología, las instituciones o en la demografía.\n",
    "\n",
    "\n",
    "###### Ejemplo 1: Tasa de participación de las mujeres en la fuerza laboral (USA)\n",
    "<img src=\"img/Picture2.png\" width=\"450\">\n",
    "\n",
    "\n",
    "Podemos modelar la tendencia de diferentes maneras, dependiendo de la dinámica de la tendencia. \n",
    "\n",
    "##### Tendencia lineal:\n",
    "\n",
    "$$ T_t = \\beta_0 + \\beta_1 TIME_t + \\varepsilon_t. $$\n",
    "\n",
    "Donde la variable *TIME* es una variable que construimos artificialmente, llamada “dummy de tiempo”.\n",
    "\n",
    "Veamos unos ejemplos de tendencia lineal al variar los parámetros:\n",
    "\n",
    "<img src=\"img/Picture3.png\" width=\"450\">\n",
    "\n",
    "Veamos ahora cómo ajusta la tendencia lineal a la serie de la participación de las mujeres en la fuerza laboral de USA:\n",
    "<img src=\"img/Picture4.png\" width=\"450\">\n",
    "Vemos que la tendencia lineal ajusta bien a la tendencia de nuestra serie. Vemos que en el resíduo no parecen quedar dinámicas relacionadas a la tendencia.\n",
    "\n",
    "<br/> \n",
    " \n",
    "###### Ejemplo 2: Volumen del New York Exchange\n",
    "<img src=\"img/Picture5.png\" width=\"450\">\n",
    "\n",
    "\n",
    "Si la tendencia que estamos buscando modelar presenta una dinámica no lineal, podemos incluir un **término cuadrático** al modelo. Lo obtenemos simplemente elevando al cuadrado a la dummy de tiempo:\n",
    "\n",
    "$$ T_t = \\beta_0 + \\beta_1 TIME_t + \\beta_2 TIME^{2}_t +\\varepsilon_t. $$\n",
    "\n",
    "Veamos qué tal ajusta nuestra tendencia cuadrática a la serie del NY Exchange:\n",
    "\n",
    "<img src=\"img/Picture6.png\" width=\"450\">\n",
    "Vemos que la tendencia cuadrática en este caso no ajusta bien a la tendencia de nuestra serie. Podemos observarlo en el residuo de nuestro modelo.\n",
    "\n",
    "Probemos modelar a la serie del NY Exchange de otra manera. Si la tendencia está caracterizada por una tasa de crecimiento constante, podemos usar un **modelo exponencial**:\n",
    "\n",
    "$$ T_t = \\beta_0 e^{\\beta_1 TIME_t}\\varepsilon_t. $$\n",
    "\n",
    "Si en lugar de modelar directamente la tendencia, modelamos su **logaritmo natural**, volvemos a tener un modelo lineal:\n",
    "\n",
    "$$ \\ln{T_t} = \\ln{\\beta_0} + \\beta_1 TIME_t + \\ln{\\varepsilon_t}. $$\n",
    "\n",
    "<img src=\"img/Picture7.png\" width=\"450\">\n",
    "Vemos que el modelo logarítmico sí ajusta correctamente a nuestra serie.\n",
    "\n",
    "Es relevante también tener en cuenta que realizar la transformación logarítmica también es útil cuando queremos estabilizar la dispersión de nuestra serie. \n",
    "\n",
    "Tenemos que tener en cuenta que debemos **revertir la transformación (back-transform)** para obtener forecasts en la escala original.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_estacionalidad\"></a> \n",
    "#### 2.2- Estacionalidad\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "Un **patrón estacional** se repite con regularidad. La estacionalidad surge de vínculos entre el calendario y las tecnologías, las preferencias o las instituciones.\n",
    "\n",
    "Por ejemplo podemos ver un patrón estacional en la venta de bebidas alcohólicas en Estados Unidos:\n",
    "\n",
    "<img src=\"img/Picture8.png\" width=\"450\">\n",
    "\n",
    "Podemos modelar la estacionalidad utilizando variables dummy. En el siguiente ejemplo modelamos una estacionalidad trimestral:\n",
    "\n",
    "<img src=\"img/Picture9.png\" width=\"300\">\n",
    "\n",
    "$$ S_t = \\sum_{i=1}^{s} \\gamma_iD_it  + \\varepsilon_t. $$\n",
    "\n",
    "Podemos agregar otro tipo de dummies, por ejemplo por días de vacaciones/feriados o ajustes por cantidad de días de comercio, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja1\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_seguir_pensando.png\" style=\"align:left\"/> </div>\n",
    "  <div style=\"float:left;width: 85%;\"><label>¿Se les ocurren otros fenómenos que podrían generar patrones estacionales? ¿Cómo los modelarían?<br/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_modelos_basicos\"></a> \n",
    "### 3- Modelos básicos para pronósticos\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "Pasemos al código para poner estos conceptos en práctica. \n",
    "\n",
    "En esta clase vamos a usar series de tiempo para predecir las ventas de medicamentos para diabetes en Australia.\n",
    "\n",
    "\n",
    "***Nota: en esta práctica guiada, vas a encontrar algunas celdas donde vas a tener que completar con tu propio código. Son pequeños ejercicios simples, para usar código que ya deberías conocer de clases anteriores o que ya se presentó en esta práctica. Completarlo te va a servir para fijar mejor los conceptos y corroborar tu comprensión del tema.***\n",
    "\n",
    "Primero importamos las librerías necesarias para trabajar con datos y visualizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.tsa.api as smt\n",
    "\n",
    "from scipy import stats\n",
    "from statistics import mode\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_eda_preprocesamiento\"></a> \n",
    "#### 3.1- Análisis exploratorio y preprocesamiento de los datos:\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "Creamos nuestro DataFrame y realizamos un ploteo inicial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/a10.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "# Función que plotea la serie:\n",
    "def plot_df(df, x, y, title=\"\", xlabel='Fecha', ylabel='Valor', dpi=100):\n",
    "    plt.figure(figsize=(16,5), dpi=dpi)\n",
    "    plt.plot(x, y, color='tab:red')\n",
    "    plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "    plt.show()\n",
    "\n",
    "plot_df(df, x=df.index, y=df.value,\\\n",
    "        title='Ventas mensuales de medicamentos para diabetes en Australia, 1992 a 2008')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploramos las primeras 5 observaciones de nuestro df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos la estacionalidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparamos los datos:\n",
    "df['year'] = [d.year for d in df.index]\n",
    "df['month'] = [d.strftime('%b') for d in df.index]\n",
    "years = df['year'].unique()\n",
    "\n",
    "# Preparamos los colores:\n",
    "np.random.seed(100)\n",
    "mycolors = np.random.choice(list(mpl.colors.XKCD_COLORS.keys()), len(years), replace=False)\n",
    "\n",
    "# Ploteamos\n",
    "plt.figure(figsize=(16,12), dpi= 80)\n",
    "for i, y in enumerate(years):\n",
    "    if i > 0:        \n",
    "        plt.plot('month', 'value', data=df.loc[df.year==y, :], color=mycolors[i], label=y)\n",
    "        plt.text(df.loc[df.year==y, :].shape[0]-.9, df.loc[df.year==y, 'value'][-1:].values[0], y, fontsize=12, color=mycolors[i])\n",
    "\n",
    "\n",
    "plt.gca().set(xlim=(-0.3, 11), ylim=(2, 30), ylabel='$Ventas$', xlabel='$Mes$')\n",
    "plt.yticks(fontsize=12, alpha=.7)\n",
    "plt.title(\"Gráfico Estacional de ventas de medicamentos\", fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los plots:\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20,7), dpi= 80)\n",
    "sns.boxplot(x='year', y='value', data=df, ax=axes[0])\n",
    "sns.boxplot(x='month', y='value', data=df.loc[~df.year.isin([1991, 2008]), :])\n",
    "\n",
    "# Seteamos los títulos:\n",
    "axes[0].set_title('Box Plot Anual\\n(Tendencia)', fontsize=18); \n",
    "axes[1].set_title('Box Plot Mensual\\n(Estacionalidad)', fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el shape de nuestro df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear una **dummy de tiempo**, es decir indicador numérico para el período de tiempo,  para poder modelar la tendencia lineal.\n",
    "\n",
    "También vamos a crear una variable que sea la dummy de tiempo elevada al cuadrado para modelar la tendencia cuadrática:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"timeIndex\"] = pd.Series(np.arange(len(df['value'])), index=df.index)\n",
    "df[\"timeIndex_sq\"] = df[\"timeIndex\"]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos variables dummy para los meses:\n",
    "dummies_mes = pd.get_dummies(df['month'], drop_first=True)\n",
    "dummies_mes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos el join entre el DataFrame con la serie de tiempo y las dummies:\n",
    "\n",
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df = df.join(dummies_mes)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer un split entre train y test, teniendo en cuenta que, al tratarse de una serie de tiempo, tenemos que poner *shuffle=False*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=12, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja1\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_seguir_pensando.png\" style=\"align:left\"/> </div>\n",
    "  <div style=\"float:left;width: 85%;\"><label>¿Qué problema metodológico generaría hacer el split con shuffle=True? <br/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos la continuidad entre los sets de entrenamiento y de testeo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos los últimos datos del set de entrenamiento:\n",
    "\n",
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos los primeros datos del set de testeo:\n",
    "\n",
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que hay continuidad entre el set de entrenamiento y el de testeo. Podemos entrenar los modelos con datos hasta septiembre de 2006 y testear con datos desde octubre en adelante, sin riesgo de data leakage. \n",
    "\n",
    "Ahora sí, pasemos a definir nuestros primeros modelos básicos de series de tiempo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_media_constante\"></a> \n",
    "#### 3.2- Media Constante:\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "La **media constante** es el modelo más básico e ingenuo de todos. Consiste simplemente en tomar la media del set de entrenamiento y utilizar ese valor para realizar predicciones. Puede usarse como un baseline para comparar otros modelos, pero difícilmente sea nuestro modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el promedio:\n",
    "model_mean_pred = df_train['value'].mean()\n",
    "\n",
    "# La predicción es fija y es la misma para el set de testeo y de entrenamiento:\n",
    "df_train[\"Mean\"] = model_mean_pred\n",
    "df_test[\"Mean\"] = model_mean_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja1\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_seguir_pensando.png\" style=\"align:left\"/> </div>\n",
    "  <div style=\"float:left;width: 85%;\"><label>¿Tendría sentido calcular la media para el set de testeo y estimar la bondad del modelo con ese valor?¿Por qué? <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploteamos los valores del set de entrenamiento y el modelo:\n",
    "df_train.plot(kind=\"line\", y = [\"value\", \"Mean\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploteamos los valores del set de testeo y el modelo\n",
    "\n",
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df_test.plot(kind=\"line\", y = [\"value\", \"Mean\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Cuán bien ajusta esta estimación?\n",
    "\n",
    "Primero definimos una función que calcula el **RMSE**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(predicted, actual):\n",
    "    mse = (predicted - actual) ** 2\n",
    "    rmse = np.sqrt(mse.sum() / mse.count())\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mean_RMSE = RMSE(df_test.Mean, df_test.value)\n",
    "model_mean_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el resultado en un DataFrame:\n",
    "df_Results = pd.DataFrame(columns = [\"Model\", \"RMSE\"])\n",
    "df_Results.loc[0, \"Model\"] = \"Mean\"\n",
    "df_Results.loc[0, \"RMSE\"] = model_mean_RMSE\n",
    "df_Results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_random_walk\"></a> \n",
    "#### 3.3- Random Walk:\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "Decimos que un proceso $ {Y_t} $ es **random walk** (sigue una trayectoria al azar si):\n",
    "\n",
    "$$ \\ {Y_t} = Y_ {t-1} + \\varepsilon,  $$\n",
    "\n",
    "siendo epsilon **ruido blanco**. Si al modelo anterior le añadimos una constante $d$, obtenemos un **random walk con deriva (with drift)**:\n",
    "\n",
    "$$ \\ {Y_t} = Y_ {t-1} + d + \\varepsilon $$\n",
    "\n",
    "Cuando nos enfrentamos a una serie de tiempo que muestra una evolución irregular, la mejor estrategia no es tratar de predecir directamente el nivel de la serie en cada período (es decir, el valor Yt), sino el cambio que ocurre de un período al siguiente (es decir, la diferencia Yt - Yt-1). **Se observa la primera diferencia (o lag) de la serie para encontrar un patrón predecible**.\n",
    "\n",
    "A los efectos del pronóstico del próximo período, puede ser tan bueno predecir el nivel como la variación, ya que el cambio predicho puede agregarse al nivel actual para generar un nivel pronosticado. El caso más simple de dicho modelo es uno que siempre predice que el siguiente cambio será cero, como si la serie tuviera la misma probabilidad de subir o bajar en el próximo período, independientemente de lo que haya sucedido en el pasado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos el desplazamiento de nuestro nuestro target en el set de entrenamiento (lag=1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"valueShift1\"] = df_train.value.shift()\n",
    "\n",
    "# La primera observación nos va a quedar en nan, la reemplazamos por el valor siguente:\n",
    "df_train[\"valueShift1\"].fillna(method='bfill', inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos el desplazamiento de nuestro nuestro target en el set de testeo (lag=1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"valueShift1\"] = df_test.value.shift()\n",
    "\n",
    "# Podemos reemplazar el primer nan con el último valor del set de entrenamiento:\n",
    "df_test.iloc[0,17] = df_train.iloc[-1,0]\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer un scatterplot entre las observaciones y su lag de un período:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(kind= \"scatter\", y = \"value\", x = \"valueShift1\", s = 50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos la diferencia entre nuestro target y el lag de un período:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"valueDiff\"] = df_train.value - df_train.valueShift1\n",
    "df_train.valueDiff.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como la perturbación aleatoria tiene media igual a cero, la predicción del Random Walk va a ser el valor del lag de un período:\n",
    "\n",
    "$$ Y_t = Y_{t-1} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"RandomWalk\"] = df_train.valueShift1\n",
    "df_train.plot(kind=\"line\", y = [\"value\", \"RandomWalk\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La predicción sobre el set de testeo es simplemente la última observación registrada en el set de entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"RandomWalk\"] = pd.Series(df_train[\"value\"][-1], index=df_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df_test.plot(kind=\"line\", y = [\"value\", \"RandomWalk\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el RMSE y almacenamos los resultados\n",
    "df_Results.loc[1, \"Model\"] = \"Random Walk\"\n",
    "df_Results.loc[1, \"RMSE\"] = RMSE(df_test.RandomWalk, df_test.value)\n",
    "df_Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que tomar la última observación del set de entranamiento mejoró significaticamente nuestras predicciones en el set de testeo respecto a tomar la media de todo el dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_tendencia_lineal\"></a> \n",
    "#### 3.4- Tendencia Lineal:\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "Continuaremos trabajando con la tendencia lineal entre value y time, fiteando nuestro modelo de regresión lineal entre \"Value\" y \"timeIndex\". En esta práctica vamos a usar la API formula de statsmodels, pero podríamos usar cualquier otra librería para realizar la regresión. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear = smf.ols('value ~ timeIndex', data = df_train).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer argumento corresponde a la forma funcional de nuestra estimación. [Más detalles](http://www.statsmodels.org/dev/examples/notebooks/generated/formulas.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos los resultados de la estimación del modelo. Vemos que la tendencia lineal es una variable significativa con un p-valor prácticamente igual a cero y que el R2 es igual a 0,853.\n",
    "\n",
    "\n",
    "Veamos las predicciones del modelo sobre el set de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"LinearTrend\"] = model_linear.predict(df_train.timeIndex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(kind = \"line\", y = [\"value\",\"LinearTrend\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos las predicciones del modelo sobre el set de testeo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df_test[\"LinearTrend\"] = model_linear.predict(df_test.timeIndex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df_test.plot(kind = \"line\", y = [\"value\",\"LinearTrend\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos el error y añadimos estos datos a nuestro DF de resultados para comparar con el modelo anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Results.loc[2, \"Model\"] = \"LinearTrend\"\n",
    "df_Results.loc[2, \"RMSE\"] = RMSE(df_test.LinearTrend, df_test.value)\n",
    "df_Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que en este caso la tendencia lineal no logra reducir el RMSE en el set de testeo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_tendencia_cuadratica\"></a> \n",
    "#### 3.5- Tendencia Cuadrática:\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "Continuaremos trabajando con la tendencia cuadrática entre value y time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora fiteamos nuestro modelo de regresión lineal entre value y timeIndex + timeIndex_sq\n",
    "\n",
    "model_quadratic = smf.ols('value ~ timeIndex + timeIndex_sq', data = df_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos el summary del modelo:\n",
    "\n",
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "model_quadratic.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la componente cuadrática es significativa, ya que también tiene un p-valor cercano a cero y el R2 mejora a 0,886. En este caso, en realidad es más correcto comparar R2 ajustados ya que estamos comparando modelos con diferentes cantidad de features. Vemos entonces que el R2-ajustado mejora de 0,852 en el modelo lineal a 0,884. Podemos ver además que tanto el AIC como el BIC se redujeron, corroborando una mejor bondad de ajuste. \n",
    "\n",
    "Veamos las predicciones del modelo sobre el set de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"QuadraticTrend\"] = model_quadratic.predict(df_train[[\"timeIndex\",\\\n",
    "                                                      \"timeIndex_sq\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(kind = \"line\", y = [\"value\",\"QuadraticTrend\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos las predicciones del modelo sobre el set de testeo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"QuadraticTrend\"] = model_quadratic.predict(df_test[[\"timeIndex\",\\\n",
    "                                                      \"timeIndex_sq\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df_test.plot(kind = \"line\", y = [\"value\", \"QuadraticTrend\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregamos las predicciones al DataFrame de testeo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadimos estos datos a nuestro DF de resultados para comparar con el modelo anterior\n",
    "df_Results.loc[3, \"Model\"] = \"QuadraticTrend\"\n",
    "df_Results.loc[3, \"RMSE\"] = RMSE(df_test.QuadraticTrend, df_test.value)\n",
    "df_Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora sí, vemos que trabajar con un trend cuadrático mejora el RMSE, llevándolo a 3,62."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_tendencia_transformacion_log\"></a> \n",
    "#### 3.6- Tendencia con transformación logarítmica:\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "Analizando los datos, vemos que la varianza de la serie aumenta con el paso del tiempo. \n",
    "\n",
    "Veamos si una transformación logarítimica con ayuda a estabilizar la varianza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['log_value'] = np.log(df_train['value'])\n",
    "df_test['log_value'] = np.log(df_test['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df(df_train, x=df_train.index, y=df_train['log_value'],\\\n",
    "    title='Log de ventas mensuales de medicamentos para diabetes en Australia, 1992 a 2008')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora fiteamos nuestro modelo de regresión lineal entre log_value y timeIndex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log = smf.ols('log_value ~ timeIndex ', data = df_train).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el summary del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "model_log.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que trabajar con la transformación logarítmica mejora la bondad de ajuste del modelo ya que el R2 ajustado es de 0,917.  Podemos ver además que tanto el AIC como el BIC volvieron a reducirse, indicando una mejor bondad de ajuste. \n",
    "\n",
    "Veamos las predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['model_log'] = model_log.predict(df_train[[\"timeIndex\"]])\n",
    "df_test['model_log'] = model_log.predict(df_test[[\"timeIndex\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almacenamos las predicciones del modelo en el set de entrenamiento y testeo luego de haber realizado back-transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['back_model_log'] = np.exp(df_train['model_log'])\n",
    "df_test['back_model_log'] = np.exp(df_test['model_log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción en el set de entrenamiento **sin** back-transformation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(kind = \"line\", y = ['log_value', 'model_log']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción en el set de entrenamiento **con** back-transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(kind = \"line\", y = ['value', 'back_model_log']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción en el set de testeo **sin** back-transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df_test.plot(kind = \"line\", y = ['log_value', 'model_log']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción en el set de testeo **con** back-transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df_test.plot(kind = \"line\", y = ['value', 'back_model_log']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadimos estos datos a nuestro DF de resultados para comparar con el modelo anterior:\n",
    "df_Results.loc[4, \"Model\"] = \"Transf Log\"\n",
    "df_Results.loc[4, \"RMSE\"] = RMSE(df_test['back_model_log'], df_test['value'])\n",
    "df_Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos una mejoría en el RMSE con el modelo logarítmico. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_tendencia_transformacion_log_estacionalidad\"></a> \n",
    "#### 3.7- Tendencia con transformación logarítmica + estacionalidad mensual:\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "Ahora fiteamos nuestro modelo de regresión lineal entre log_value y timeIndex más las dummies de mes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log_est = smf.ols('log_value ~ timeIndex + Aug + Dec + Feb + Jan + Jul + Jun + Mar + May + Nov + Oct + Sep',\\\n",
    "                          data = df_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log_est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja1\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_seguir_pensando.png\" style=\"align:left\"/> </div>\n",
    "  <div style=\"float:left;width: 85%;\"><label>¿Todos los meses son significativos?<br/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que al agregar las dummies mensuales, la bondad del modelo mejora sustancialmente. El R2 ajustado pasa de 0,917 a 0.987. Por otro lado, vemos que los coeficientes de todos los meses son significativos, con excepción del mes de marzo, cuyo p-valor es de 0,332. Podríamos volver a entrenar el modelo sin el mes de marzo para ver si mejora. En este caso también, los criterios AIC y BIC se redujeron, confirmando la mejoría en la bondad de ajuste indicada por el R2 ajustado.\n",
    "\n",
    "\n",
    "Calculamos las predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['model_log_est'] = model_log_est.predict(df_train[[\"timeIndex\", \\\n",
    "                                              \"Aug\", \"Dec\", \"Feb\", \"Jan\",\\\n",
    "                                               \"Jul\", \"Jun\", \"Mar\", \"May\",\\\n",
    "                                                \"Nov\", \"Oct\", \"Sep\"]])\n",
    "\n",
    "\n",
    "df_test['model_log_est'] = model_log_est.predict(df_test[[\"timeIndex\", \\\n",
    "                                              \"Aug\", \"Dec\", \"Feb\", \"Jan\",\\\n",
    "                                               \"Jul\", \"Jun\", \"Mar\", \"May\",\\\n",
    "                                                \"Nov\", \"Oct\", \"Sep\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almacenamos las predicciones del modelo en el set de entrenamiento y testeo luego de haber realizado back-transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['back_model_log_est'] = np.exp(df_train['model_log_est'])\n",
    "df_test['back_model_log_est'] = np.exp(df_test['model_log_est'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción en el set de entrenamiento **sin** back-transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(kind = \"line\", y = ['log_value', 'model_log_est']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción en el set de entrenamiento **con** back-transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(kind = \"line\", y = ['value', 'back_model_log_est']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción en el set de testeo **sin** back-transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df_test.plot(kind = \"line\", y = ['log_value', 'model_log_est']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción en el set de testeo **con** back-transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df_test.plot(kind = \"line\", y = ['value', 'back_model_log_est']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Results.loc[5, \"Model\"] = \"Transf Log + est\"\n",
    "df_Results.loc[5, \"RMSE\"] = RMSE(df_test['back_model_log_est'], df_test['value'])\n",
    "df_Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que al modelar la estacionalidad mensual agregando las variables dummy, nuestro modelos mejora sustancialmente, reduciéndose el RMSE de 3,25 a 2,05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_exponential_smoothing\"></a> \n",
    "#### 3.8- Single Exponential Smoothing:\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "El **suavizamiento exponencial simple** otorga más importancia a la información reciente y menos a la pasada. En su forma más simple podemos expresarlo como:\n",
    "\n",
    "$$ \\widehat{y_t} =\\alpha . y_{t-1}  + (1 - \\alpha ) . \\widehat{y}_{t -1} $$\n",
    "\n",
    "Aquí el modelo es un promedio ponderado entre el valor actual y el valor anterior del modelo.\n",
    "$\\alpha$  se conoce como smoothing factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "\n",
    "model_exp_smoothing = SimpleExpSmoothing(df_train.value).fit(smoothing_level=0.3,\\\n",
    "                                                            optimized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(kind = \"line\", y = \"value\")\n",
    "model_exp_smoothing.fittedvalues.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Time Series Cross Validation \n",
    "\n",
    "Antes de comenzar a construir un modelo, veamos primero cómo optimizar los hiperparámetros del modelo automáticamente.\n",
    "\n",
    "¿Cómo podemos hacer para realizar validación cruzada con series de tiempo? Las series de tiempo tienen una estructura temporal y no se pueden mezclar los valores aleatoriamente en una partición mientras se conserva esta estructura. Con la aleatorización, se perderán todas las dependencias temporales entre las observaciones. Es por esto que tendremos que usar un enfoque más complicado para optimizar los parámetros del modelo. Utilizaremos es \"cross validation on a rolling basis\".\n",
    "\n",
    "La idea es bastante simple: entrenamos nuestro modelo en un pequeño segmento de la serie de tiempo desde el principio hasta algunas t, hacemos predicciones para los siguientes t + n pasos y calculamos un error. Luego, expandimos nuestra muestra de entrenamiento a valor t + n, hacemos predicciones desde t + n hasta t + 2 ∗ n, y continuamos moviendo nuestro segmento de prueba de la serie de tiempo hasta que alcanzamos la última observación disponible. Como resultado, tenemos folds como n cabrá entre la muestra de entrenamiento inicial y la última observación\n",
    "\n",
    "<img src=\"img/ts_validation.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "Aplicamos un split entre train y test para series de tiempo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit \n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con fines ilustrativos, vamos a hacer un print de los elementos del set de entrenamiento y validación para cada fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, val_index in tscv.split(df_train):\n",
    "    print(\"TRAIN:\", train_index, \"VAL:\", val_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una función que aplica time series cross validation para el modelo single exponential smoothing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def timeseriesCVscore_exp_smoot(alpha, series):\n",
    "    \"\"\"\n",
    "        Returns error on CV  \n",
    "        \n",
    "        params - vector of parameters for optimization\n",
    "        series - dataset with timeseries\n",
    "        slen - season length for Holt-Winters model\n",
    "    \"\"\"\n",
    "    # creamos un array de errores:\n",
    "    errors = []\n",
    "    \n",
    "    values = series.values\n",
    "    \n",
    "    # instanciamos el objeto que realiza el tscv:\n",
    "    tscv = TimeSeriesSplit(n_splits=5) \n",
    "    \n",
    "    # Aplicamos cross validation:\n",
    "\n",
    "    for train, test in tscv.split(values):\n",
    "    \n",
    "        model = SimpleExpSmoothing(values[train]).fit(smoothing_level=alpha,\\\n",
    "                                                             optimized=False)\n",
    "        \n",
    "        predictions = model.forecast(len(test))\n",
    "        actual = values[test]\n",
    "    \n",
    "        error = mean_squared_error(predictions, actual)\n",
    "        errors.append(error)\n",
    "        \n",
    "    return np.mean(np.array(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.001, 0.01, 0.1, 0.2, 0.3, 0.35, 0.4, 0.5, 0.7]\n",
    "errors = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    error = timeseriesCVscore_exp_smoot(alpha, df_train.value)\n",
    "    errors.append(error)\n",
    "\n",
    "print('Alpha óptimo:', alphas[np.argmin(errors)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo optimizado:\n",
    "\n",
    "model_exp_smoothing = SimpleExpSmoothing(df_train.value).fit(smoothing_level=alphas[np.argmin(errors)],\\\n",
    "                                                             optimized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"Simple_Smoothing\"] = model_exp_smoothing.forecast(12)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_simp_smo_RMSE = RMSE(df_test[\"Simple_Smoothing\"], df_test.value)\n",
    "model_simp_smo_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.plot(kind=\"line\", y = [\"value\", \"Simple_Smoothing\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el RMSE y almacenamos los resultados\n",
    "df_Results.loc[6, \"Model\"] = \"Simple Smoothing\"\n",
    "df_Results.loc[6, \"RMSE\"] = RMSE(df_test[\"Simple_Smoothing\"], df_test.value)\n",
    "df_Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploteamos las mejores estimaciones \n",
    "df_test.plot(kind = \"line\", y = [\"value\", \"RandomWalk\", \"back_model_log_est\",\\\n",
    "                                                 \"back_model_log\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_modelos_ciclos\"></a> \n",
    "###  4- Modelos de Ciclos para Series de Tiempo\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "Vamos ahora a modelar la **componente cíclica** de las series de tiempo. \n",
    "\n",
    "Recordemos que podíamos descomponer a una serie de tiempo de la siguiente manera:\n",
    "\n",
    "$$ y_t = T_t + S_t + C_t + \\varepsilon_t. $$\n",
    "\n",
    "Por **ciclos** se entiende cualquier tipo de dinámica no capturada por la tendencia o la estacionalidad.\n",
    "\n",
    "Estamos ante la presencia de ciclos cuando observamos algún tipo de dinámica mediante la cual el presente está vinculado al pasado. No tiene por qué ser un ciclo rígido.\n",
    "\n",
    "Los ciclos son más complejos de analizar que la tendencia y la estacionalidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_series_estacionarias\"></a> \n",
    "#### 4.1- Series Estacionarias\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "Solamente podemos trabajar con ciclos si tenemos series estacionarias. Comencemos por definir qué es una **serie estacionaria en sentido débil** o **estacionaria en la covarianza**:\n",
    "\n",
    "$$ 1)\\hspace{1cm}E(y_t) = \\mu,  \\forall t. $$\n",
    "$$ 2)\\hspace{1cm}Var(y_t) = \\gamma < \\infty,  \\forall t. $$\n",
    "$$ 3)\\hspace{1cm}Cov(y_t, y_{t-k}) = \\gamma_k < \\infty,  \\forall t,k. $$\n",
    "\n",
    "\n",
    "\n",
    "1) Nos indica que la esperanza de $y_t$ es constante a lo largo del tiempo, es decir que no depende de t.\n",
    "\n",
    "2) La varianza debe ser un valor constante y finito para todo t.\n",
    "\n",
    "3) La autocovarianza es la covarianza de la variable contra sí misma en otros momentos del tiempo. Debe depender solamente de la traslación k y no de t.\n",
    "\n",
    "Ejemplo de serie estacionaria:\n",
    "\n",
    "<img src=\"img/Picture10.png\" width=\"750\">\n",
    "\n",
    "Si bien la mayoría de las series no son estacionarias, es posible trabajar con modelos que tratan con los componentes no estacionarios (como el trend y la estacionalidad) de modo tal de que el componente cíclico remanente sea estacionario.\n",
    "\n",
    "En el ejemplo de abajo, vemos que el residuo de la serie, una vez modelada la tendencia, es una serie estacionaria:\n",
    "\n",
    "<img src=\"img/Picture7.png\" width=\"450\">\n",
    "\n",
    "Alternativamente, podemos realizar transformaciones a nuestra serie para hacerla estacionaria. Podemos por ejemplo aplicar **diferenciaciones** de diferente orden para estabilizar la media o aplicar **transformaciones Box-Cox** para estabilizar la varianza. \n",
    "\n",
    "###### Test de Dickey-Fuller\n",
    "\n",
    "Para evaluar la estacionariedad de una serie utilizamos el test de Dickey-Fuller (DF), o el test de Dickey-Fuller aumentado (ADF). \n",
    "\n",
    "•Si partimos del modelo $X_t = rX_{t-1} + u_t$\n",
    "\n",
    "•Donde -1≤ r ≤ 1\n",
    "\n",
    "•Si r=1 estamos en el caso de raíz unitaria y la serie no es estacioria (el Random Walk no es una series estacionaria).\n",
    "\n",
    "•El test de Dickey-Fuller (DF) se basa en la siguiente regresión:\n",
    "    $DX_t = dX_{t-1} + u_{t}$ , donde $d = (r-1)$\n",
    "\n",
    "•La hipótesis nula $H_0$ es que los datos son no estacionarios \n",
    "\n",
    "•$H_0$ se rechaza si el estimador de d es negativo y significativamente diferente de cero.\n",
    "\n",
    "En el DF se supone que el $u_t$ no está autocorrelacionado. El ADF contempla esta posibilidad adicionando al DF los valores rezagados de la variable dependiente. La $H_0$ es idéntica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a calcular los resíduos del mejor modelo que tenemos hasta ahora, el modelo con transformación logarítmica y dummies estacionales.\n",
    "\n",
    "Probamos primero si los residuos del modelo en la serie original son estacionarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_model = df_train['value'] - df_train['back_model_log_est']\n",
    "\n",
    "plt.plot(df_train.timeIndex, res_model, '-');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos el test de Dickey-Fuller al resíduo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testeamos la estacionariedad de los residuos:\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "result = adfuller(res_model)\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "for key, value in  result[4].items():\n",
    "    print('Valor crítico %s: %.2f' % (key,value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No podemos rechazar la $H_0$ con un nivel de significación del 5%. Probamos ahora con los residuos antes de realizar back transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_log_est = df_train['log_value'] - df_train['model_log_est']\n",
    "\n",
    "plt.plot(df_train.timeIndex, res_log_est, '-');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testeamos la estacionariedad de los residuos:\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "result = adfuller(res_log_est)\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "for key, value in  result[4].items():\n",
    "    print('Valor crítico %s: %.2f' % (key,value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos rechazar la $H_0$. Avanzamos con el modelado de los ciclos de los residuos del modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_modelo_arima\"></a> \n",
    "#### 4.2- Modelo ARIMA\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "El modelo ARIMA sin estacionalidad surge por la combinación de:\n",
    "* un modelo Auto-Regresivo AR(p), basado en la diferenciación o rezago de la serie y\n",
    "* un modelo de media móvil MA(q).\n",
    "\n",
    "Su denominación es producto de las siglas en inglés: **AutoRegressive Integrated Moving Average** model.\n",
    "\n",
    "Veamos un mayor detalle de los dos modelos que componen ARIMA:\n",
    "\n",
    "##### Modelos Auto-Regresivos - AR (p)\n",
    "\n",
    "En un modelo de autorregresión, pronosticamos la variable de interés usando una combinación lineal de valores pasados de la variable en cuestión. El término autoregresión indica que es una regresión de la variable contra sí misma. Por lo tanto, un modelo de **orden autorregresivo (p)** se puede escribir como:\n",
    "\n",
    "$$ y_t = c + \\phi_1 y_{t-1} + \\phi_2 y_{t-2} + \\phi_3 y_{t-3} + .. \\\\ $$\n",
    "El Random Walk es un modelo AR (1) con $$ \\phi_1 = 1,  c = 0 \\\\ $$ El Random Walk with drift (deriva) $$ \\phi_1 = 1,  c \\ != 0 \\\\ $$\n",
    "\n",
    "Normalmente restringimos los modelos autorregresivos a datos estacionarios; también pueden ser necesarias algunas condiciones sobre los valores de los parámetros. Para un modelo AR (1), la condición de estacionariedad se determina como: $$ |\\phi_1| < 1 $$.\n",
    "\n",
    "##### Modelo de media móvil - MA (q)\n",
    "\n",
    "En lugar de utilizar valores pasados de la variable a pronosticar mediante una regresión, un modelo de media móvil usa **shocks inobservables presentes y pasados** en un modelo similar a una regresión.\n",
    "\n",
    "$$ y_t = c + e_t + \\theta_1 e_{t-1} + \\theta_2 e_{t-2} + ... + \\theta_q e_{t-q} \\\\ $$\n",
    "\n",
    "donde **$e$ es ruido blanco**. Nos referimos a esto como un modelo **MA (q)**, donde $q$ representa la **cantidad de rezagos** considerados en el modelo. Por supuesto, no observamos los valores de $ {e_t} $, por lo que no es realmente regresión en el sentido habitual.\n",
    "\n",
    "Veamos que cada valor de $ {y_t} $ se puede considerar como una media móvil ponderada de los últimos errores de pronóstico. Sin embargo, los modelos basados en la media móvil no deben confundirse con el suavizado del promedio móvil. Se usa un modelo de promedio móvil para pronosticar valores futuros, mientras que el suavizado promedio móvil se usa para estimar el ciclo de tendencia de valores pasados.\n",
    "\n",
    "##### Modelo ARIMA \n",
    "\n",
    "El modelo completo se puede escribir como:\n",
    "\n",
    "* **Número de términos AR (autorregresivos) (p)**: los términos AR son solo rezagos de la variable dependiente. Por ejemplo, si *p* es 5, los predictores para  $ {y_t} $  serán  $ y_{t-1} $, $ y_{t-2} $  ... y  $ y_{t-5} $ .\n",
    "\n",
    "* **Número de términos MA (promedio móvil) (q)**: los términos MA son errores de pronóstico rezagados en la ecuación de predicción. Por ejemplo, si *q* es 5, los predictores para $ {y_t} $ serán $ {e_t} $, $ e_{t-1} $, $ e_{t-2} $ ... $ e_{t-5} $ donde $ {e_t} $ es la diferencia entre el valor estimado y el valor instantáneo y real.\n",
    "\n",
    "* **Número de diferencias (d)**: son las diferencias no estacionales que necesitamos para la estacionariedad. Entonces, o podemos pasar la variable diferenciada y poner d* = 0 o pasar la variable original y poner d* = d. Ambos generarán los mismos resultados.\n",
    "\n",
    "Una preocupación importante aquí es cómo determinar el valor de *p* y *q*. Usamos dos vías para determinar estos parámetros, veamos:\n",
    "\n",
    "* **Función de autocorrelación (ACF)**: es una medida de la correlación entre la serie y su rezago, también se conoce como la función de autocorrelación total. La ACF en el rezago *k*, denotada por $ \\rho_k $, se define como:\n",
    "\n",
    "$$ \\rho_k = \\frac {\\gamma_k} {\\gamma_0} $$\n",
    "\n",
    "* **Función de autocorrelación parcial (PACF)**: mide la correlación entre la serie y su rezago después de eliminar las variaciones ya explicadas por las comparaciones intermedias. Por ejemplo, en el desfasaje 5, comprueba la correlación tras eliminar los efectos ya explicados por los rezagos 1 a 4.\n",
    "\n",
    "En el modelo MA, el ruido (shock) se desvanece rápidamente con el tiempo. En sentido opuesto, el modelo AR tiene un efecto muy duradero del shock. De ahí que, mientras el primero se enfoca en períodos cortos de tiempo, el segundo prioriza el más largo plazo.\n",
    "\n",
    "Importamos plots ACF y PACF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos la ACF para res_log con 20 rezagos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_acf = acf(res_log_est, nlags = 20)\n",
    "lag_acf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almacenamos la ACF en una Serie de Pandas y la ploteamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACF = pd.Series(lag_acf)\n",
    "ACF.plot(kind = \"bar\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos la PACF para res_log con 20 rezagos. Usamos mínimos cuadrádos ordinarios para estimar los parámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_pacf = pacf(res_log_est, nlags=20, method='ols');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almacenamos la PACF en una Serie de Pandas y la ploteamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PACF = pd.Series(lag_pacf)\n",
    "PACF.plot(kind = \"bar\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir una función que va a plotear una serie y nos va a dar información sobre su estacionariedad y sobre sus ACF y PACF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsplot(y, lags=None, figsize=(12, 7), style='bmh'):\n",
    "    \"\"\" \n",
    "        Plotea la serie de tiempo, el ACF y PACF y el test de Dickey–Fuller\n",
    "        \n",
    "        y - serie de tiempo\n",
    "        lags - cuántos lags incluir para el cálculo de la ACF y PACF\n",
    "        \n",
    "    \"\"\"\n",
    "    if not isinstance(y, pd.Series):\n",
    "        y = pd.Series(y)\n",
    "        \n",
    "    with plt.style.context(style):    \n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        layout = (2, 2)\n",
    "        \n",
    "        # definimos ejes\n",
    "        ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2)\n",
    "        acf_ax = plt.subplot2grid(layout, (1, 0))\n",
    "        pacf_ax = plt.subplot2grid(layout, (1, 1))\n",
    "        \n",
    "        y.plot(ax=ts_ax)\n",
    "        \n",
    "        # obtengo el p-value con h0: raiz unitaria presente\n",
    "        p_value = sm.tsa.stattools.adfuller(y)[1]\n",
    "        \n",
    "        ts_ax.set_title('Análisis de la Serie de Tiempo\\n Dickey-Fuller: p={0:.5f}'\\\n",
    "                        .format(p_value))\n",
    "        \n",
    "        # plot de autocorrelacion\n",
    "        smt.graphics.plot_acf(y, lags=lags, ax=acf_ax)\n",
    "        # plot de autocorrelacion parcial\n",
    "        smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax)\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corremos la función con nuestra serie res_log:\n",
    "\n",
    "tsplot(res_log_est, lags=36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el gráfico nos sugiere valores para $p$ y para $q$. \n",
    "\n",
    "En este caso tenenemos: $p = 3$ y $q = 3$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el modelo ARIMA de statsmodels\n",
    "\n",
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instancio el modelo con parámetros ($p=3$, $d=0$, $q=3$) según el análisis de ACF y PACF.\n",
    "\n",
    "En este caso $d=0$ porque trabajamos directamente con una serie estacionaria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ARIMA = ARIMA(res_log_est, order=(3,0,3))\n",
    "\n",
    "# Estimo el modelo:\n",
    "results_ARIMA = model_ARIMA.fit()\n",
    "results_ARIMA.fittedvalues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos un print de los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_ARIMA.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el coeficiente ma.L1 no es significativo, pero como los rezagos de orden mayor sí lo son, dejamos los 3 coeficientes en el modelo. \n",
    "\n",
    "Ploteamos la serie res_log_est y las estimaciones del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,3.5))\n",
    "res_log_est.plot()\n",
    "results_ARIMA.fittedvalues.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos el método plot_predict():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ARIMA.plot_predict(end=len(df['value']));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizamos los residuos del modelo ARIMA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ARIMA =  results_ARIMA.fittedvalues - res_log_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsplot(res_ARIMA, lags=36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No parecería haber más estructura en los resíduos que podamos capturar. Nuestro resíduo ahora es ruido blanco.\n",
    "\n",
    "Con el método forecast() podemos hacer predicciones out-of-sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_ARIMA, se, conf = results_ARIMA.forecast(len(df_test['value']), alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incorporamos el efecto cíclico a nuestro modelo, sin realizar back-transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['log_model_ARIMA'] = df_train['model_log_est'] + results_ARIMA.fittedvalues\n",
    "\n",
    "df_test['log_model_ARIMA'] = df_test['model_log_est'] + predictions_ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(kind = \"line\", y = ['log_value', 'log_model_ARIMA']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.plot(kind = \"line\", y = ['log_value', 'log_model_ARIMA']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos back-transformation al modelo logarítmico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['back_log_model_ARIMA'] = np.exp(df_train['log_model_ARIMA'])\n",
    "\n",
    "df_test['back_log_model_ARIMA'] = np.exp(df_test['log_model_ARIMA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción con back-transformation en el set de train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df_train.plot(kind = \"line\", y = ['value', 'back_log_model_ARIMA']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los resultados de la predicción con back-transformation en el set de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POR FAVOR COMPLETÁ CON TU CÓDIGO:\n",
    "df_test.plot(kind = \"line\", y = ['value', 'back_log_model_ARIMA']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos el RMSE y lo almacenamos en nuestro DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Results.loc[7, \"Model\"] = \"Log Model + est + ARIMA\"\n",
    "df_Results.loc[7, \"RMSE\"] = RMSE(df_test['back_log_model_ARIMA'], df_test['value'])\n",
    "df_Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el modelo que combina la tendencia, la estacionalidad y el ciclo es el que performa mejor de todos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja7\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/en_resumen.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <br>  \n",
    "  <div style=\"float:left;width: 85%;\"><label><b>En conclusión...</b></label></div>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Podemos descomponer una serie de tiempo en:\n",
    "\n",
    "- **Tendencia**: componente “permanente”, el efecto persiste en el largo plazo. Se puede interpretar como lo que motiva el cambio a largo plazo de la media.\n",
    "- **Estacionalidad**: esta componente aporta movimientos periódicos a la serie.\n",
    "- **Ciclos**: se entiende por cualquier tipo de dinámica no capturada por la tendencia o la estacionalidad. Estamos ante la presencia de ciclos cuando observamos algún tipo de dinámica mediante la cual el presente está vinculado al pasado. No tiene por qué ser un ciclo rígido.\n",
    "- **Componente aleatoria**: son shocks que no presentan un efecto duradero, ya que las suponemos i.i.d. con media 0 y varianza constante.\n",
    "\n",
    "De manera aditiva, podemos decir entonces que: \n",
    "\n",
    "$$ y_t = T_t + S_t + C_t + \\varepsilon_t. $$\n",
    "\n",
    "- Para modelar la tendencia y la estacionalidad podemos usar dummies de tiempo y estacionales. \n",
    "\n",
    "- Para modelar los ciclos usamos modelos ARIMA. Para modelar modelos ARIMA necesitamos que las series sean estacionarias. Las condiciones de estacionariedad son: \n",
    "\n",
    "$$ 1)\\hspace{1cm}E(y_t) = \\mu,  \\forall t. $$\n",
    "$$ 2)\\hspace{1cm}Var(y_t) = \\gamma < \\infty,  \\forall t. $$\n",
    "$$ 3)\\hspace{1cm}Cov(y_t, y_{t-k}) = \\gamma_k < \\infty,  \\forall t,k. $$\n",
    "\n",
    "\n",
    "Podríamos directamente comenzar a trabajar modelando los ciclos, sin pasar por la tendencia y la estacionalidad, pero en ese caso antes deberíamos asegurarnos de que la serie es estacionaria o realizar transformaciones para que lo sea, como por ejemplo diferenciar o aplicar transformaciones de Box-Cox.\n",
    "\n",
    "###### Recordar que nuestro objetivo principal es que los resíduos de la serie sean ruido blanco, es decir que no quede más estructura en la serie que podamos extraer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja7\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_saber_mas.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <br>  \n",
    "  <div style=\"float:left;width: 85%;\"><label><b>Para saber más:</b></label></div>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Pueden explorar dos recursos muy interesantes para trabajar con series de tiempo: Prophet y tsfresh:\n",
    "\n",
    "[Prophet](https://github.com/facebook/prophet)\n",
    "\n",
    "[tsfresh](https://tsfresh.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[volver a TOC](#section_toc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
